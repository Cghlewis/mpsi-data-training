---
title: "Training 2: Data Collection Structures"
output: 
  html_document:
    css: "css/custom.css"
    toc: TRUE
    toc_float: TRUE
    anchor_sections: FALSE
---

<br>

:::presentation
<br>
You can view slides from this talk: In Progress
:::

---

## Overview

---

In this training I continue to cover establishing systems that help make a project successful. These structures are the backbone of your project and without them in place, it can create many, many headaches for project staff, can compromise the confidentiality of your data, and may even make your data unusable. 

If you are collecting your own original data as part of your study, for example a randomized controlled trial study, data management best practices should be interwoven throughout your data collection process. I will discuss the role of data management in data collection design, tracking of participants and data collection, as well as data storage and security. I will not go in to the ins and outs of project management, including things such as recruiting participants, consenting participants, training data collectors, or scheduling data collection as those are less tied to data management and more aligned with project coordination. However, I will note that it is important to work with your data manager on the language used in your consent form. If you plan to share your data upon conclusion of your project, either via a repository or your own data request system, you will want to make sure your consent has clear language about your intent to share your de-identified data. If applicable, also include language regarding your intent to collect identifying information in a master list/key for tracking purposes that will be stored separately from your de-identified data. Shero and Hart from Florida State University have a great [Informed Consent Template](https://figshare.com/articles/preprint/Informed_Consent_Template/13218773/1). 

[Meyer (2018)](https://journals.sagepub.com/doi/10.1177/2515245917747656) has several helpful dos and donts for language to use in your consent form including:

‚úîÔ∏è Don't promise to destroy your data (unless your funder explicitly requires it)  
‚úîÔ∏è Don't promise to not share data  
‚úîÔ∏è Do get consent to retain and share data  
‚úîÔ∏è Do incorporate data-retention and sharing clauses into IRB templates  
‚úîÔ∏è Do be thoughtful when considering risks of re-identification (ex: small sample size for sub-groups)  
‚úîÔ∏è Don't promise that research analyses of the collected data will be limited to certain topics  

Other helpful consent resources:

 üìë [Within & Between podcast](https://open.spotify.com/episode/7cP4u3gimblEo8S8Z37UZA)  
 üìë [University of Pittsburgh](https://www.hrpo.pitt.edu/data-security-guidance)  
 üìë [University of Guelph](https://www.uoguelph.ca/research/support-document/i-need-create-master-list-link-participant-id-numberscodes-my-data-what-should-i))  
 üìë [ICPSR](https://www.icpsr.umich.edu/web/pages/datamanagement/confientiality/conf-language.html)   
 üìë [Shero and Hart: Working with your IRB](https://figshare.com/articles/preprint/Working_with_your_IRB_Obtaining_consent_for_open_data_sharing_through_consent_forms_and_data_use_agreements/13215305/1)

Final note before diving into this content: Before any project begins, all data collection instruments and protocol must be submitted to an Institutional Review Board (IRB) for approval. The IRB, a formal organization designated to review and monitor human participant research, ensures that the welfare, rights, and privacy of research participants are maintained throughout the project. Some of the systems I cover throughout this series will be vetted by an IRB (ex: original data collection), others will not (ex: documentation, style guide). This training will not cover the ins and outs of the IRB, but I wanted to note that while this training provides many suggestions for setting up your data collection systems, you must always have required forms approved by IRB before moving forward with original data collection.

---

## Data Collection Instruments

---

When it comes to the intersection of data management and data collection, there is a lot to consider. If at all possible, take some planning time to create data collection instruments and procedures that keep your data secure, valid, minimize errors, and relieve future data cleaning headaches. I am going to cover some common instruments teams create to collect original data, and ways you may be able to make these more streamlined and efficient instruments.

**Quick note**: Everything you read below is from my personal experience as well as a summary of what I have heard while interviewing other researchers. As such I may be missing out on even better ways to set up these systems. I am open to feedback!

<br>

### Surveys

Research teams may be restricted in how they collect their survey data due to limited resources, research design, or even the population being studied. However, if at all possible, I highly recommend collecting surveys using software/web-based tools that directly feed into a table or database rather than through paper forms. The reasons are:

* Forms are easier to maintain/update
* Reduces cost and effort of manual printing and collating
* Easier to track completion
* More efficient than manually entering or manually scoring data (including TeleForm)
* It reduces errors in both data collection as well as data entry/scoring
* Can reduce missing data
* Quick turnaround of clean data 
* Removes the need to physically store paper data
* Allows for assigning correct variable names, value codes, and labels within the form
* Provides more data privacy than paper data
* Bonus: Streamlines pipeline for real-time reporting/dashboarding options
* Bonus: Able to use crowdsourcing options such as MTurk and Prolific

**Note**: With the COVID-19 pandemic in 2020, I think many of us doing education research have had to make a huge switch, very quickly, to collecting data electronically and remotely. This is yet another reason to create/utilize web-based data collection instruments in particular, to prepare for the unknown, and provide flexibility to collect data even when you aren't able to physically be in schools. 


#### **Web-based Surveys**

There are many web-based survey platforms (Ex: Qualtrics, Survey Monkey, Google Forms) you can use to develop surveys. If those existing platforms do not meet your needs, you can always build your own web-based application to collect data. 

  + You can hire a developer to build an app for you
  + You can build your own application to collect data in tools such as R or Tableau
  
No matter what platform you use, building your survey requires some up front planning. First and foremost make sure to build a survey that is both valid and reliable. Secondly, take time to think how the data you collect will be *translated into a database*. Remember, every question answered is then stored in a database within the platform that you will later download to a file. Here are several suggestions to adhere to when creating your survey that will provide you with more accurate data and reduce future data management headaches (*While I will not provide a tutorial for how to implement each suggestion, they are all possible in a platform such as Qualtrics*):  

  1. Name all your survey items the correct item name from your data dictionary (Ex: Rename the Qualtrics default Q1 to s_gender)
      - This isn't a name that your survey participants will see, but it is the variable name you will see when you download your data
  1. Code all values as they are in your data dictionary (Ex: 1=strongly agree, 2= agree, etc.)
      - In Qualtrics you can do this using the "recode values" option
  1. Use data validation to reduce errors and missing data
      - Content validation:
        - Make GPA a numeric only field (restrict the number of digits)
        - Make birth date a date only field
      - Response validation
        - Force response (a respondent must answer the question to move forward)
        - Request response (notifies the respondent that they skipped a question and asks if they still want to move forward)
  1. If there is a finite number of response options, and the number isn't too large (less than ~ 20) use a drop-down list rather than open-ended field
      - School Name as a drop-down removes the potential for people to enter school names differently (some which you may not be able to decipher)
        + ("South Middle School", "South Middle", "SOUTH", "Soth Mid")
  1. If there is an infinite number of response options or the number of options is large, use an open text box. 
      - Consider limiting the number of characters allowed in the text box unless you want to allow users to write paragraphs of information.
      - Using open ended text boxes does not mean you can not re-group this information into categories later through syntax. It is just more time-consuming and requires interpretation and decision making on the part of the data cleaner/analyst.
  1. Only ask for one piece of information per question
      - Don't ask: Please list your ACT or SAT score.
      - Do ask: Please list your ACT score.  Please list your SAT score. In separate questions.
  1. Make your question wording abundantly clear
      - Don't ask: Are you from this county?
      - Do ask: Do you currently live in this county?
  1. Make the question format the same across studies. For continuity, it is a good practice to keep variable names and formats the same within and across studies.
      - If *anxiety1* was a slider question, on a scale from 1-10, with one point increments in a previous study, build this question the same way in the next study
  1. Do make your response options clear in the question
      - Don't ask: Which parent are you? (m/f)
          - Does m=male or mother?
      - Do ask: Which parent are you? (mother/father/legal guardian/other)

##### Feedback

  + If you are unsure if your survey is going to download the way you want it to, make some sample data! Send the survey to a few staff members and have them take the survey using a "test" name. Then you can download the sample data and see if it looks the way you expect it to. You can always remove this test data either within the survey platform itself or delete it during your cleaning process. 
  + Sending your survey out to staff to test is also a great opportunity to get feedback! Was there any language that was unclear? Did you forget some skip logic? Did you leave off an option or maybe an entire question? Get this feedback early as it is very difficult to make changes mid-project!  
  
 üìë [Pew Research](https://www.pewresearch.org/methods/u-s-survey-research/questionnaire-design/) and [Qualtrics](https://www.qualtrics.com/blog/10-tips-for-building-effective-surveys/) both provide comprehensive best practices in questionnaire design.

#### **Offline Surveys**

If your site or participants do not have WiFi and/or email access, one option is to work with a survey platform (such as Qualtrics) that allows you to create a survey online, administer it using an offline survey app on your phone or tablet, and then upload that data back to the survey platform once you have an internet connection again.

Still, depending on your study, participants, and resources, building a web-based survey may not be possible and/or it may not be the best option for your project. If you must collect paper survey data I recommend the following to reduce error:

  + Have very clear instructions/training on how to complete the paper form, and check for missing data in the field
  + Check all forms for missing data when they return back to the office
  + Consider using something like [TeleForm](https://ocrsolution.com/teleform-software/)
    + I personally have not used this but I know TeleForm designs machine readable forms that can later be scanned rather than hand entered
  + If staff are hand entering data into a database or spreadsheet (rather than using Teleform), set up clear databases for staff to enter the data
      + Restrict entry in fields (only allow numeric values if you want staff to enter numbers rather than the actual words associated with response options)
      + Have very clear instructions for data entry, including what they should do if they come across missing data (skip the cell, enter a certain number such as -999, etc.)
      + Set up a system for error checking    
        - Consider double entering either all or a percentage of your data and running a syntax to check for errors (I will discuss this more in later trainings)

   üìë Reynolds and Schatsnieder from Florida State University have some great suggestions [here](https://figshare.com/articles/preprint/The_Basics_of_Data_Management/13215350/1) for setting up a data entry station for any manual data entry that needs to occur.

### Assessments

For the same reasons I recommend web-based tools for surveys, I also recommend web-based tools for assessments.

#### **Web-based Assessments**

If a web-based option already exists for your assessment, the obvious answer is to simply use this. For example the Renaissance STAR assessment is administered online. 

However, if your assessment is only available in paper form (such as the BASC-3), consider converting it to a web-based form if at all possible. You can do that in several ways:

  1. Build the assessment into an online survey platform.
  2. Build your own application to collect data.
  - If you build the assessment into your own app or into a survey platform, set it up using the same recommendations for web-based surveys (ex: back end coding to match the actual values on the forms, back end naming variables correctly, etc.)

Once data is collected, proceed with scoring as usual, following the guidelines of the specific assessment.

#### **Offline Assessments**

If there are no web-based options, or connecting to WiFi is not an option for your project, then of course, keep with the paper assessments and follow the guidelines of the specific assessment. If the assessment requires any manual scoring (such as the Woodcock Johnson), be sure to implement an error checking system (such as the one mentioned in the paper surveys section).
  
### Observations

Classroom observations, qualitative or quantitative, can be collected using a web-based tool. 

#### **Web-based Observations**

Observation forms can be built into an online survey platform or your own application that data collectors can access on their phones, tablets or laptops in the field. If the observation has duration codes, you can build this into your app or there are existing applications that have built in timers. If the observation simply needs to last X amount of minutes, use a web-based form and you can always just have observers set timers on their phones, similar to what they may do using a paper form.

#### **Offline Observations**

If WiFi is not available to you in the field, consider making a form that still eliminates the need for data entry (so not a paper form) and that ideally connects to or creates some type of database or table. Then have data collectors enter data into this form on a device in the field. This does not have to be high-tech. It could simply be: 

  - An excel file that is pre-built with every field available and the options for each field are limited to only the correct options through a drop-down list.
  - Create an Access form that is connected to a database
  - Utilize the offline survey options provided by tools such as Qualtrics (see Offline Surveys section)
  - Build or use existing offline tools. For duration code classroom observations, we've used [software](https://mooses.vueinnovations.com/) built by a developer at Vanderbilt to collect frequency and duration observation data. It stores observation text files to the data collectors device. 

Collecting electronic data in the field becomes tricky when you are having people use tools simultaneously that aren't connected to a shared database (such as separate excel files or Access databases). When you use a survey platform everyone's data is feeding into the same database/table. However, when you are using separate Excel files for instance, everyone is storing data on their own device. This requires you to set up a way for collectors to share files (ex: Dropbox, Box, or whatever your institution deems is a secure system) and then for you to merge those files together across data collectors. It is definitely trickier, although possibly still a more efficient and reliable method that paper forms and hand entry of data. 

### Interviews or Focus Groups

I don't work much with qualitative data so I won't say much here. Interviews and focus groups are typically recorded (at least audio) whether they are collected in-person or online. Then if you transcribe (some people simply just take notes), transcription is either outsourced to a company, done in-house, or done using transcription software and is usually kept in something such as a word document or Google doc. For this type of qualitative data, I have no preference for how it is collected and transcribed as long as the transcription is accurate and it is a format that is appropriate for any analysis software you plan to use.

### Secondary Data Sources

If you receive any non-public, confidential, secondary data sources, such as school district records, just make sure you ask for them in a format that is usable to you. For instance, I have received school district records in PDF form, and while, after much data wrangling it **can** be usable, it would be much easier to request to receive this information in tabular format.

### Consents

Consents and assents can also be collected through secure web-based tools, such as Qualtrics or DocuSign. It does however, require your participants to have access to the internet and/or email. Consult with your IRB to see what tools are approved.

### All-in-One Study

Last I wanted to mention that it is also possible to build all or almost all of your study into one tool (depending on your study). Using a tool like Qualtrics, or building your own tools in applications like R Shiny, you can build your consent, randomization, study ID assignment, survey and assessment all in one tool that participants can access in one simple link. Lucy D'Agostino McGowan has a great example in her slides [here](https://docs.google.com/presentation/d/1FtI4KeX3C8cFBJi0NeTURqfXphrQ2W8sxoDQAd7LrRo/edit#slide=id.p).


## Security in the Field

Researchers are always balancing participant confidentiality with maintaining accurate data. IRB requires that participants should **not know their study IDs** and you should **never have a document that has both participant name and study ID** on the same form. However, if your study is longitudinal, maintaining the accuracy of your participant IDs is critical to linking data over time.

If you are collecting data longitudinally and need to de-identify it, some ideas to handle Study IDs in data collection are the following:

### Web-based Data:

  + When sending out web-based surveys/assessments to participants, here are a few options (this is not all-inclusive):  
    - Send individual links to participants (where each survey link is connected to a study ID within the system). This can usually be done easily in a survey platform using a *panel*. 
      + This is the most error-proof way to ensure study IDs are entered correctly. You load in IDs directly from your tracking database so that when data is downloaded, the correct ID is already linked to each participant.
    - Send one link to all participants and assign all participants a double ID to enter into the survey (they enter this ID rather than their name). That double ID is added as a new field in your tracking database, which houses your study IDs. When the data is downloaded, a data manager will need to link the study ID to the double ID and then remove the double ID from the data. 
      + This can possibly introduce error if a participant enters their double ID incorrectly
    - Send one link out to all participants and have each participant enter their name. 
      + This may be the most problematic out of all the options in terms of data management, privacy, and potential for errors. When the data is downloaded, the study ID must be linked based on participant name and participant name promptly deleted (to remove all identifying information) and oftentimes participants may not record their name exactly as it is in your tracking database, leading to matching errors.
  + Similar methods can be used for other electronic data collected in the field using forms on tablets or phones.  
  
Other considerations to maintain electronic data privacy include:

  - Add a line to your survey introduction, instructing participants to close their browser at the completion of their survey so that others may not access their responses.
  - If you are collecting anonymous data, make sure to not collect IP addresses as they can be used to identify an individual's computer
  - **An important one**: Make sure you are using and/or building data collection and storage tools that are approved by your IT department and are considered secure for the level of sensitivity of data you are collecting. 
  - Make sure your in-field data collection devices (phone, tablet, laptop) are password secured and never left open and unattended and all identifiable information is encrypted (data is encoded so that only those with a password can decipher it). It is also possible to encrypt an entire device, protecting data from being transferred across application. You may also consider remote wiping capabilities on portable devices in case of loss or theft [J-PAL](https://www.povertyactionlab.org/sites/default/files/Data_Security_Procedures_December.pdf).


### Offline Data:

  + If you take paper forms into the field with participant names on them, consider doing the following to link those names to IDs at a later time:  
    - Write the participant ID on the form and then use a removable label with participant name and place that over the ID. That way the participant never sees the ID, and when you return to the office, you can remove the name label, shred it, and be left with only the ID on the form.  
    - Write the name on the form, and when the form returns to the office, use a black permanent marker to black out the name and then write the ID on the form before entry. I like this less, because there is still a chance you will be able to see the name through the marker.  
    - If you need the name in the field (to identify students), but you also need the ID in the field (say to enter on a data collection form) then consider having one sheet with names with a double ID (such as 1,2,3,4) and another sheet that connects the double ID to the true study IDs. These two lists could obviously also be housed on a password protected tablet or phone in the field for additional security. 
    
```{r, echo=FALSE, fig.align="center", out.width='60%'}

knitr::include_graphics("img/twotables.png")

```

Other considerations to maintain paper data privacy include:

  - Make sure all paper forms are kept in a folder (or even a lock box) with you at all times in the field and they are promptly returned to the office and stored according to your IRB security rules, typically behind two locked doors (ex: in a locked room, in a locked file cabinet).  


Resources:

  üìë [University of Guelph](https://www.uoguelph.ca/research/print/1947) 

---

## Tracking

---

There are many pieces of information to track for a research study including:

  + Consent and assents
  + Participant information
  + Incentives/Payments
  + Data collection completion
  + Participant movement
  
And all of these needs to be tracked across time (waves and cohorts) and space (classrooms and sites). Tracking is handled by the project coordinator to monitor project completion, however, it is extremely helpful to consult with a data manager when setting up these systems to make sure you include all relevant pieces and to make sure the database is understandable when it comes time to work with the data. Not only is a thorough and complete tracking database vital to ensuring you collect all of your data, it is also vital to project coordination, consort diagram creation, and final dataset verification. At some point, a data manager will use a tracking database to confirm that the N they have in their clean data match the N in a tracking database and it is crucial that tracking is complete and easy to understand.

:::question
**Quick thought: Tracking Best Practices**

A few best practices for tracking that improve project coordination and data management:

  - Only track data that you physically have
    + Never track data that someone tells you they collected
      + Mark that info in "Notes" and track when you have the physical/electronic data
  - Track daily throughout data collection
    + Don't save tracking until the end of data collection
    + This improves the accuracy of your tracking as well as your project coordination
  - Only track complete data
    + If a survey is only partially completed and you plan to send it back out for completion, mark this in the notes but do not mark it as completed
:::

<br>

### Creating a Tracking Database

A tracking database (sometimes called a master list because it contains data that links your assigned study IDs to their identifiable information) can be set up in software or an app such as:

  + Microsoft Access
  + Excel
  + QuickBase
  + RedCap
  + Salesforce
  + Qualtrics
  + A relational database, maintained using a SQL database engine such as [SQLite](https://datacarpentry.org/sql-socialsci/), MySQL, or PostgreSQL.

The possibilities really are endless and it all depends on what your team has access to and how tech-savvy your team is. Some systems require specific programming knowledge (ex: setting up a SQL database). It really doesn't matter too much but I will say I personally prefer using a relational database system, which allows relating tables to one another, eliminating redundant data. Without getting too technical, [database normalization](https://en.wikipedia.org/wiki/Database_normalization) increases performance, decreases storage, and makes it much easier to make updates to tables as changes occur. There are many options out there, but Access is just one example of a tool that allows you to relate tables and allow some form of querying.

Consider this first structure, with 3 very simple tables (a student table, a teacher table, and a school table). Each table has a primary key that makes individuals within that table unique and each table can be connected through a foreign key. For example in the student table, the primary key is `studentid` and the foreign key is `teacherid` which connects students to the teacher table. Using a query language (such as SQL) in systems such as Access, we can pull multiple tables together ad hoc to make a table with all the pieces of information we need.

```{r, echo=FALSE, fig.align="center", out.width='70%'}

knitr::include_graphics("img/tables.png")

```

Say for example, in an effort to get more students in our study, we wanted to send out emails to teachers who have had low student consent numbers for our study. To get the information we need to send those emails, we could easily run a query, such as this SQL query, that joins the student and teacher tables by `tch_id` and then counts the number of students consented by teacher name and includes teacher email:

`SELECT Teacher.tch_name, Teacher.tch_email, COUNT(Student.stu_id) AS num_consented`  
`FROM Student INNER JOIN Teacher ON Student.tch_id = Teacher.tch_id`  
`WHERE Student.assent_complete='Yes'`  
`GROUP BY tch_name, tch_email;`


And we would get this informative table.

```{r, echo=FALSE, fig.align="center", out.width='70%'}

knitr::include_graphics("img/tables4.png")

```

Now consider these 3 tables that are not relational (such as 3 tabs in an excel spreadsheet). Since we are unable to set up a system that links these tables together, we need to enter redundant information into each table (such as teacher or school name) in order to see that information within each table without having to flip back and forth across tables to find the information we need.

```{r, echo=FALSE, fig.align="center", out.width='70%'}

knitr::include_graphics("img/tables2.png")

```

Using a relational structure allows us to eliminate redundant data. This not only saves us time and energy but reduces errors as well. You can imagine how useful that is.  

  + You don't have to type things like teacher name and school name over and over for every student in the student table.  
  + When a teacher changes their last name, you don't have to go back to the student table and update that last name for all of their students.  
  
  üìë [Database vs. Spreadsheet](https://bus206.pressbooks.com/chapter/chapter-4-data-and-databases/)
  
When setting up your tables consider the following:

  + Create one table per entity (entities being participants, sites, districts, etc.)
    - Student table, Teacher table, School table, District table
  + Consider how you want to track data over time and across cohorts or waves
    - Do you want to track each cohort in a separate table, or keep them all in the same table and add a cohort column to track that information?
    - Do you want to track longitudinal data all in the same table or make a different for each wave of data collection?
    - I have no preference here. It is more streamlined to keep all waves in the same table, but I think for some people it can be overwhelming to have fall, winter, and spring, for example, all tracked in the same table
  + Make sure to include both primary and foreign keys in all tables
    
Other preferences for a tracking system include:  

  + One that restricts entry values to reduce error (only allow yes/no for a field, or a drop-down list of school names)  
  + A system with versioning as you will be constantly updating and adding to your tracking system and there may be times when you need to check an older version  
  + A system that allows querying of data (pull tables of information as needed such as rosters, or percent of surveys collected per classroom)  
  + One that easily allows export of data if you need to print rosters or print labels, etc.  

### Tracking Database Fields to Include

Fields to consider tracking in your database at the beginning of your study include:

  + Study ID/Location ID (Primary ID and Foreign Keys)
  + Participant/Site name
  + Contact information
  + Other IDs necessary for linking data (such as a state ID for linking to student school records)
  + Relevant study demographics (such as date of birth, grade level, gender, or zip code)
  + Schedule information needed for the study (block, class time)
  + Consent/Assent received
  + Randomization info (cohort, group)
  + Payment information (ex: W9)
  + Double IDs if you use these for data collection

Fields to track over time (for each period you collect data):  

  + Data collected (for each unique piece of data)  
      + Observation collected (yes/no)  
      + Interview collected (yes/no)  
      + Survey collected (yes/no)  
  + Movement (ex: track if a student moved out of the school during fall data collection)  
  + Notes (ex: This is where you want to track ANYTHING you may need to remember at a later time such as reasons for missing data, errors in the data, etc.)  
  + Payment/Incentives provided  
  + Other optional pieces to collect:  
      + Attempts to collect data  
      + Communication with the participant  
      + Dates data collection completed  
    
Example of a very simplified student table:

```{r, echo=FALSE, fig.align="center", out.width='120%'}

knitr::include_graphics("img/table3.png")

```


Last, if your study is an RCT, you will also want to keep randomization information tracked as well so that information can be added to your analysis data at a later time. This will most likely be stored separate from your tracking database if you plan to keep individuals, such as project coordinators, blinded to treatment condition. 

:::question
**Quick thought: Study IDs**

As you recruit and consent participants, you will add these participants to a tracking database under an assigned study ID (ex: *stu_id*, *tch_id*). These IDs allow participants to remain confidential in your research data. That ID (typically a 2-6 digit random numeric or alphanumeric value) will follow that individual throughout the life of the study and should be **unique** to that individual. This number **never changes**.

Depending on your study design, some participants **may** have the opportunity to be re-recruited into the study more than once. For example, we had a study where three cohorts of 5th grade students were recruited over three years. Therefore, the same 5th grade teachers were often recruited back into the study each cohort. If you have a similar study design, you **still** keep that same study ID (in this case the same *tch_id*) for that participant. If you want to identify the unique wave or cohort that a participant is brought back into the study, make sure you have other variables in your data that help you understand why a study ID occurs in your data more than once (ex: Having a *cohort* variable).

```{r, echo=FALSE, fig.align="center", out.width='60%'}

knitr::include_graphics("img/IDtable.png")

```
:::

<br>

Although data storage is our next topic, I want to mention right now, that this tracking database (master list) clearly has identifiable and protected information. Therefore it should be stored securely and apart from all other study data. This is the only file that directly links your participants' true identity to your confidential study data and it should never be stored in the same folder as your study data. Additionally, it should have limited access. Only those who need access, such as the project coordinator and data manager, should have access to this file for security purposes. 

Resources:

  üìë [University of Guelph](https://www.uoguelph.ca/research/support-document/i-need-create-master-list-link-participant-id-numberscodes-my-data-what-should-i)     
  üìë [Florida International University](http://research.fiu.edu/irb/data-management-security/)  
  üìë [Poverty Action Lab](https://www.povertyactionlab.org/sites/default/files/Data_Security_Procedures_December.pdf)  
  
---

## Data Storage

---

Whether you are working with your own original collected data, or you are working with data provided to you from an entity such as a school district, or you are working with publicly available data, you need to consider secure data storage. 

In general you will most likely be working with one of four types of data and will need to store your data according to the type of data:

  + Anonymous data (Data at no time has ever had identifying information tied to it and can never be linked back to an individual)
  + Confidential data (Personally identifiable information (PII) in your data has been removed and names are replaced with a code and the only way to link the data back to an individual is through that code. Identifiers are stored separate from the research data in your tracking database/master list.)
  + De-identified data (Data is considered de-identified when all PIIs are removed and there is no longer a link to a participant's identity anywhere; i.e., all names are replaced with a code and all tracking databases/master lists that link to that code are destroyed at the conclusion of a study)
  + Identifiable data (Data that includes personally identifiable information (PII))
    - PII includes any of the following (and more):
      + Name
      + Address
      + Zipcode
      + Email
      + SSN
      + DOB
      + Phone number
      + District or School Name
      + District/School ID (attached to school records)

For this section I am going to generally describe the level of security needed to store your data depending on the type of data. However, I am **not** a security expert and in an effort to not explain security incorrectly, I would like to refer readers to this document from [J-PAL](https://www.povertyactionlab.org/sites/default/files/Data_Security_Procedures_December.pdf). It is one of the most comprehensive documents I have come across regarding data security.


### Storing a Tracking Database

Because your tracking database/master list contains identifiable information about your participants, this data must have the highest security. The specifics of this security will be set by your university or institution. However, the general rules for storing this type of data is:

  + They should be stored separately from your confidential study data
  + This data should have limited access (only available to the few individuals who actually need to interact with this data)
  + It should be stored on a password-protected, university/institution sponsored shared network or cloud service with encryption (never a personal computer)
  + Since this is your only crosswalk between your study IDs and PIIs, make sure to backup this data regularly
  + Last, although I discussed writing consents so that you do not need to destroy data at any point after study completion, you can and should plan to destroy your tracking database/master key after all study data is cleaned and de-identified and your study is completed. The timeline for destroying this key after study completion may be dependent on the data retention plan required by your IRB, so consult with them for further details.
  
### Storing Electronic Records

Your typical study data files are in formats such as csv, tab-delimited, excel, text, word doc, or a statistical program file such as .sav, .dta, .R, or .sas. No matter the file type, your study data should all be de-identified/confidential, only including study IDs and no other identifiers. However, there are still some security precautions you should take.

  + It should be stored on a password-protected university/institution sponsored shared network or cloud service
  + Limit access to your data folder to only those who need to work with the data. This ensures no one intentionally or unintentionally makes changes to your data.
  + Have a data backup policy ([DataONE](https://old.dataone.org/best-practices/create-and-document-data-backup-policy))
  + School record data you acquire from schools and districts may have its own set of regulations such as [(FERPA)](https://studentprivacy.ed.gov/audience/researchers) so it is worth checking that your storage meets those requirements as well.
  
### Storing Detachable Media

  + This includes items such as external hard drives, flash drives, or CDs
  + Store behind two locked doors
  + Do not store at a personal residence or leave in a vehicle
  + Password protect these items
  
### Storing Audio/Video Data

A newer type of data collection is occurring since the COVID-19 pandemic, and that is observations, interviews, and focus groups occurring via video conferencing. This data is especially sensitive as it may include names and faces as part of the recording. Again, you will want to refer to your specific institution guidelines, but generally:

  + You will want to use approved software that is licensed by your Institution
  + You will want to make sure that software and cloud storage is HIPPA and/or FERPA-compliant if you need it to be
  + Conduct the the video call in a secure/private location
  + If recording the session, make sure that participants are notified that the session is being recorded
  + Sessions are stored on an Institution approved cloud service or managed service
  + Once transcripts are created from the data, make a plan to destroy recordings

Note: These same data security rules will also apply to data that is recorded in person. And furthermore, any data that is recorded on detachable media will need to follow the detachable media guidelines.

  
### Storing Paper Data

  + Your paper data should be de-identified/confidential (names removed). 
    + An exception to this is if you collect paper consents/assents which typically have participant name/signature on them. 
  + As I mentioned earlier in this training, a typical IRB rule is to store paper data behind two locked doors for security. This typically means a locked file cabinet behind a locked door. 
  + Never store paper data at a personal residence or leave in your vehicle
  + When transporting data from a site to your office, consider keeping your files in a lock box and use a personal vehicle for transportation rather than public transit.
  
  
### Sharing data

These rules all come from [J-PAL](https://www.povertyactionlab.org/sites/default/files/Data_Security_Procedures_December.pdf).

  + Choose secure methods of file transfer
    - Upload encrypted files to cloud storage that is approved by your institution
    - Email an encrypted file, sharing the password separately
    - Mailing encrypted files stored on an encrypted device
  + How **not** to share data:
    - Never share data with PII via email
      - This includes even a password-protected excel file
    - Never mail unencrypted media (ex: flash drives)
    - Don't upload unecrypted data to cloud storage


### General Security Rules

Again, I am not an IT professional, but some general security rules to keep in mind for all data and devices are:

  + Make regular back-ups of your data
    - Have a policy in place for who will perform and check the backups, what the backup schedule will be, and where the backups will be stored (a location separate from the original data)
  + Password protect your devices (with strong passwords)
  + Never leave a device open and unattended. Lock your device and go offline when not in use.
  + Don't send confidential data via email
  + Keep your virus protection up to date
  + Use encryption at all points in the data flow (from collection to storage)
  + Encrypt any identifiable data on portable devices
  + If any identifiable information is collected, promptly replace it with study IDs and delete/destroy identifiable information as soon as possible after data collection
  + Only provide access to those who need access to your data, and remove access when people are no longer affiliated with your institution or the study
  + Never store identifiable information on your desktop
  + Consider having staff review and sign a data responsibility agreement that discusses the ways they will work with the data ethically, responsibly, and securely
  + When deleting data, consider using data erasing software to remove sensitive data.
  + Have a data security plan, in writing, for every project (who has access to what data, what happens when someone leaves the team, data retention period, data sharing plan, data training requirements)
  + There are [data classification levels (DCL)](https://www.umsystem.edu/ums/is/infosec/classification-definitions) that help you identify the security you need based on the type of data you have. Knowing what level your data falls under can help you start conversations with your IT department to decide if you are meeting the level of security you need to meet FERPA and HIPPA requirements if applicable.
  + Last, talk with your IT staff for recommendations on storage, security, and file sharing. They are the experts!

<br>

:::question
**Quick thought: Institutional Server**

While some institutions may allow cloud storage, [J-PAL](https://www.povertyactionlab.org/sites/default/files/Data_Security_Procedures_December.pdf) suggests possible benefits to using a institution provided server if available are:  

  * Your IT department may provide secure remote access via VPN, typically involving multiple layers of security including encrypting network connections and requiring two factor authentication  
  * IT staff may be able to automate secure data backups for you  
  * IT staff may be able to restrict access to folders for you  

:::

<br>

Resources on data security:

  üìë [University of Guelph](https://www.uoguelph.ca/ccs/sites/uoguelph.ca.ccs/files/Categorization%20%26%20Security%20of%20Research%20Data_Final.pdf)  
  üìë [University of Pittsburgh](https://www.hrpo.pitt.edu/data-security-guidance)  
  üìë [University of Michigan](https://research-compliance.umich.edu/data-security-guidelines)  
  üìë [Princeton University](https://ria.princeton.edu/human-research-protection/data/best-practices-for-data-a)  
  üìë [University of Nevada](https://www.unr.edu/research-integrity/human-research/human-research-protection-policy-manual/410-maintaining-data-confidentiality)  
  üìë [Pacific University Oregon](https://www.pacificu.edu/academics/research/scholarship-and-sponsored-projects/research-compliance-integrity/institutional-review-board/irb-policies-recommended-practices/data-security-storage)  
  üìë [Florida International University](http://research.fiu.edu/irb/data-management-security/)  
  üìë [DataONE](https://old.dataone.org/best-practices/create-and-document-data-backup-policy)  
  üìë [IPA](https://www.poverty-action.org/sites/default/files/publications/IPA-Best-Practices-for-Data-and-Code-Management-Nov-2015.pdf)  
  üìë [Karl Broman](http://kbroman.org/dataorg/pages/backups.html)  
  üìë [University of Missouri](https://www.umsystem.edu/ums/is/infosec/research-data-security)  
  üìë [Foundational Practices of Research Data Management](https://riojournal.com/article/56508/instance/5569681/)

---

## Directory Structure

---

No matter where your team stores your files, it is important to develop a logical directory structure. It makes it so much easier to find your files and it facilitates sharing within and outside of your team. You will want to build this structure into your style guide and implement it generally across all of your projects to create cohesion. The most important thing is to allow files to be findable, have a structure that allows you to control user access, and to keep folders shallow enough that you don't reach a limit on the allowable length of a path name for any file.

At the highest, organizational level, you will want to have separate folders for each of your projects, as well as an overall *Team* folder that houses general documents related to your team functioning (meeting notes, hr documents, team expectations). You will want to develop a style guide that covers general rules across all folders and house that style guide in an easily accessible location (ex: Team Wiki and/or a README in each project folder)

Then, within each project folder you will want to build a hierarchy something like this:

```{r, echo=FALSE, comment=NA}
library(data.tree)

project2 <- Node$new("project-new")
  lifecycle <- project2$AddChild("life-cycle-folder")
    time <- lifecycle$AddChild("time")
      datatype <- time$AddChild("data-type")
        participant <- datatype$AddChild("participant")
          archive <- participant$AddChild("archive")
          
print(project2)

```

  - Level 1: The name of the project

  - Level 2: General research life cycle folders (Ex: data, documentation, project management, intervention, tracking)

  - Level 3: For longitudinal studies I tend to like the third level to be time period or grouping sub-folders (Ex: cohort 1, or wave 1)

  - Level 4: Specific data type folders (Ex: raw data, syntax, clean data) 

  - Level 5: Participant specific folder (ex: student, teacher).
  
  - Level 6: All previous versions of files can go in here to reduce clutter

More details on setting up this structure can be found in [training_3](https://cghlewis.github.io/mpsi-data-training/training_3.html).


Resources:

  üìë [Helsinki University Library](https://zenodo.org/record/1914401#.YAh46ehKhPZ)
