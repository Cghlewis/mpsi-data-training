---
title: "Training 1: Documentation"
author: "Crystal Lewis  "  
output: 
  html_document:
    css: "css/custom.css"
    toc: TRUE
    toc_float: TRUE
---

<br>

:::presentation
<br>
You can view slides from this talk [here].
:::
  
---

## Data Management Plan

---

To increase transparency and to advance scientific inquiry in education research, the Institute of Education Science ([IES](https://ies.ed.gov/funding/datasharing_implementation.asp)) has a policy on providing access to your data at the conclusion of projects funded through their research centers (*Exploration* or *Initial Efficacy and Follow-Up* grants). The plan for sharing data must be laid out in a data management plan (DMP) which is included as an appendix in your grant application. Among other things, the DMP must include the following:  

‚úîÔ∏è Type of data to be shared  
‚úîÔ∏è Procedures for managing and maintaining confidentiality  
‚úîÔ∏è Roles and responsibilities of project staff in the management of research data  
‚úîÔ∏è Expected schedule for data sharing (no later than the publication of findings and at least for 10 years)  
‚úîÔ∏è Format of the final dataset  
‚úîÔ∏è Documentation to be provided  
‚úîÔ∏è Method of data sharing  
  + You may take on the responsibility of data sharing yourself
  + Or, use a data archive
‚úîÔ∏è Whether or not a data sharing agreement specifies the conditions under which the data will be shared  
‚úîÔ∏è Any circumstances that prevent any data from being shared  
‚úîÔ∏è Most recent rule: A plan for [pre-registering](https://ies.ed.gov/seer/preregistration.asp) your study within the first year of the project  

This training is not specific only to IES grants. Almost all funders that education researchers may work with require a DMP that also includes a data sharing or archival plan (ex: [NIJ](https://nij.ojp.gov/funding/research-development-and-evaluation-grant-award-requirements#vj8jg) and [NIH](https://grants.nih.gov/grants/policy/data_sharing/data_sharing_guidance.htm#doc)). Furthermore, this training will not cover the details of writing up a DMP but rather how to implement a DMP. We will cover topics such as: How do we document data; How do we track it; How do we manage it; How do we keep it secure; and How do we share it. This specific training module will cover documentation.

Before we dive in, as IES is the most prolific funder of RCTs in education, if you are someone who will be writing IES DMPs in the future or want to know more about them, here are some excellent resources:

üìë [University of Virginia IES DMP template](https://data.library.virginia.edu/files/IES-Data-Management-Plan-Template-2018.docx)  
üìë [IES DMP tool](https://dmptool.org/template_export/1895.pdf)  
üìë [IES most recent Request for Applications](https://ies.ed.gov/funding/pdf/2021_84305A.pdf)

---

## Documentation

---

Data Documentation is not only required by funders including IES, it is essential for data management. 
It also allows us to: 

* Track decisions/changes made throughout the life cycle of the project  
* Make our decisions/analyses replicable   
* Clean our data with fidelity  
* Ensure others use and interpret our data accurately  
* Discover errors in our data  
* Allows others to find our archived data through metadata

Documentation can take many forms. [IES](https://ies.ed.gov/funding/datasharing_implementation.asp) states that they expect documentation to "be a comprehensive and stand-alone document that includes all the information necessary to replicate the analysis performed by the original research team" and should include:  

* a summary of the purpose of the data collection  
* methodology and procedures used to collect the data  
* timing of the data collection  
* details of the data codes, definition of variables, variable field locations, and frequencies  

However, a) IES provides no template for how documentation is laid out OR what tools to use to create/share this information and b) outside of IES required documentation for data sharing, there may be additional documentation your team may want to keep to help manage internal processes. 

We will go over types of documentation you may want to consider keeping. Many of these documents have overlapping information and some terms may be used interchangeably in the field (ex: Data Dictionary and Codebook or README and metadata). Also, some of the documents are important to start day one of the project, while others are more important to create at the end of the project when you are ready to share data. The point of this next section isn't to implement all of these documents, but rather to consider which documents capture the information you need to have a successful project. It may just be a protocol and a data dictionary. Or it may be a protocol, a data dictionary and a readme for each data file. Or it may be all of these documents! It depends on things such as the scale of your project and how you plan to share the data at the end of your project.

<br>

### üìì Protocol

A document/s to record all your procedures changes made to those procedures throughout the grant.

At some point someone will ask you how or why you did something the way you did. This is the document that will save you because it is very likely that you will not remember. I highly recommend always adding protocol as part of any data documentation plan. Protocol does not have to be broken out in a separate document, it can be included in other documentation such as your Codebook or ReadMe. However, this may be best created as a standalone document. Most likely your protocol will not be shared outside of your team, but the information in your protocol can be used to inform other documentation such as READMEs or Codebooks. Your protocol can live in any format that works for you (ex: .docx, .md, .txt). It is a living document that will be continually updated so use a format that makes sense for you. 

Protocol should cover procedures/decisions for the following:

* Participant recruitment
* Consent and assent
* Participant selection
* Randomization and blinding/unblinding
* Data collection (including correspondence to set up data collection)
* Staff training
* Data entry, data retrieval, data scoring
* Payments/Incentives
* Intervention implementation

These procedures can be broken out into separate documents or in one larger document with a table of contents. Either way, each section of your protocol should have the following to track project changes:

* Date the protocol was made    
* Who made the protocol  
* Any rationale behind the protocol  
* Any related documents or research behind this protocol  
* For any changes to the protocol after the project has begun add the following below the original protocol   section:  
  + Revision Date  
  + Who decided on the revision  
  + Any rationale behind the revision  
  + Any related documents or research behind the revision
  
It is also good practice to add a copy of your data collection instruments to your protocol (Surveys, Interview Questions, etc.), as well as changes/versions of those and explanations for the changes.
  
üìë These [slides](https://figshare.com/articles/Data_Management_and_Data_Management_Plans/7890827) from Jessica Logan, Ph.D. have nice protocol examples.

<br>

### üìì Wiki

I am including wiki in here, even though I think it is uncommon to hear about this in education research. However, to me, a wiki is similar to a protocol document in that is a project implementation tool, used by project staff. If you use certain tools such as Microsoft SharePoint, a wiki can be a great place to store high level project information that your team frequently refers to. SharePoint describes a wiki as "a site that is designed for groups of people to quickly capture and share ideas by creating simple pages and linking them together." It is a page that anyone on your team can add/edit content and then can link to those documents for easy access (ex: provide information about and link to recruitment documents). You can also house important data management rules such as file naming conventions, file structure, versioning rules, and so forth here [**note: If you do not have a wiki, I still recommend documenting these data management rules somewhere that is easily accessible for project staff, possibly a README housed in your main project folder**].

You can make wikis with many other tools, but you can read more about Sharepoint's wiki [here](https://support.microsoft.com/en-us/office/create-and-edit-a-wiki-dc64f9c2-d1a2-44b5-ac59-b9d535551a32).

There is a great episode of the [Education Data Chat](https://www.buzzsprout.com/1074286/5185513-episode-5-organizing-shared-network-drives-tips-and-tricks) podcast where they discuss wikis as well.

<br>

### üìì Data Dictionary

A data dictionary is another essential document to keep and I highly suggest you start this before your ever collect a piece of data. This will help you set up successful back end coding as you create data collection tools as well as being a document you can refer back to as questions come up about the data. It is also a document that can be shared with others to better understand your data. This document is usually in rectangular form, for example an excel spreadsheet, google sheet or something similar that has rows and columns. It includes all information relevant to every variable in your data. 

Here is a nice [example](https://media.screensteps.com/image_assets/assets/001/878/671/original/8fbcc565-602f-4ac6-b828-2eaaeb67578b.png) of a data dictionary.

In order to start a data dictionary, you need to **know** the following:

* What data are we collecting? (Ex: Student Assessment, Teacher Observation, Teacher Survey, Principal Interview)
* What are the questions/measures included in the surveys?
* What is your variable naming protocol?
  + Have you used the question/measure before? If yes, keep the variable name the same across projects.
  + A typical variable naming convention for survey questions is AbbreviatedScaleName# (Ex: toca1, toca2, toca3)
    + If the question wording or response options change during the project, make a rule for versioning
      + Ex: Add "v2" on revised questions (toca1v2)
  + Be consistent with capitalization (ex: always using lowercase)
  + Be consistent with delimiters (ex: use snakecase or camel case)
    + Camel case (TocaConcentration)
    + Snake case (toca_concentration)
  + No spaces or special characters in variable names
  + Make sure all variable names are unique
  + Names should be meaningful but concise (Ex: SPSS cannot handle variable names over 64 characters)
* Do our measures have pre-determined value coding rules or can we assign our own?
* Are we collecting data over time? What is our Cohort/Year/Time variable protocol?
  + If you plan to collect multiple time points of data and merge data in a wide format, you will need a time prefix or suffix on your variables (ex: toca1_T1 or toca1_Fall)
  + If you plan to track a cohort over multiple years in wide format, you may need a second prefix or suffix (ex: toca1_Year1_T1)
  + If you plan to merge data in long format, time can be their own variables (Ex: Time, Year, Cohort)
  
Your Dictionary should capture information such as:

* Variable Name  
* Variable Label  
* Exact question text  
* Value range or Value codes  
* Measurement unit (Ex: numeric, string, date)  
* How is missing data coded  
* Variable universe (Who gets this question, Is it skipped for some people)  
* What time periods/years does this variable exist  
* Notes (such as versions/changes to this variable)  
* Summary statistics 
* Also consider grouping variables by measure

You may even consider having separate data dictionaries per expected final dataset. So for example, if you plan to have a final teacher dataset and a final student dataset, you may want to have a student dictionary and a teacher dictionary rather than stating teacher or student in the universe column.

Last, as I mentioned before, it is important to start this document BEFORE ever collecting data. But that doesn't mean that you will be able to fill in all the cells before collecting the data. Fill in what you can. You should be able to fill in the data you have control over. For example, if you are making and administering the survey, you should be able to know what variables will be in that data, how you want to name them, and how they should be coded. However, you may not know this information for other data until after data collection. For example, if you are administering a 3rd party assessment, you may not know what the downloaded data is going to look like until after you have collected the data and it has been scored. Also, other fields such as notes, time periods, and maybe even summary statistics are those that will be continually updated throughout the project.

<br>

### üìì Codebook

Like a data dictionary, a codebook also captures variable information, as well as project level information. It should capture all a user would need to know in order to understand and correctly interpret your data. It is typically part of the metadata that is added to a data archive, or is given to those who request your data after the project is complete. It usually takes the form of a plain text file (.txt), pdf (.pdf), or extensible markup language (.xml), rather than a proprietary form such as .docx. Several statistical programs (including R, SPSS, SAS and Stata) will export simple codebooks for your final datasets.

Here is a nice example of a [codebook](https://ddialliance.org/sites/default/files/06551.pdf).

Your codebook should captures things such as:

* Study title  
* Names of Investigators  
* Table of contents  
* Purpose and format of the codebook  
* Variable level details  
  + Variable name  
  + Variable label  
  + Question text  
  + Coded values (1,2,3,4)  
  + Value labels (Excellent, Good, Fair, Poor)  
  + Summary statistics  
  + Missing data values  
  + Skip patterns  
  + Notes  
  + If data is in text format, indicate position of each variable
* Computations for weights (if applicable)
* Imputation (if applicable)

Other optional content for a codebook: 

* Data collection instruments 
* Consent agreements
* Methodological details  
* Related publications  
* Flowchart of data collection instruments  

*Last, I have found that sometimes the term data dictionary is synonymous with codebook. I don't think the name matters, but for the sake of this training I am specifying a data dictionary as the document in tabular form with only variable level information and a codebook as a document usually in text format. You can keep either or both types of documentation. I think the data dictionary as laid out in this training is the easier document to update throughout the life of the project and assists with project implementation, while I view the codebook as a document to summarize the final datasets at the end of the project (and to be included with data archives/requests).*

<br>

### üìì README

A README is a plain text (.txt), markdown (.md), pdf (.pdf), or extensible markup language (.xml), standalone file that explains a project. These files are most known for their use in programming, but have become more prevalent in research. It is recommended to make one README file per dataset. This standalone document will accompany each dataset. It should be named so it is easily associated with the dataset and it should be housed in the same folder the data is in. 

A README can capture the following:  

* Project level information
* File information
* Access information
* Methodology
* Codebook (you can include your .txt codebook in this document for instance)

Because so much information can be included in these files and there is already great websites that describe README files in detail, I will not go into further detail. 

Excellent examples and further details can be found here:

[README template](https://cornell.app.box.com/v/ReadmeTemplate) from Cornell is excellent and can be tailored to your needs.  
[README recommended content: UCI](https://guides.lib.uci.edu/datamanagement/readme)  
[README recommended content: Cornell](https://data.research.cornell.edu/content/readme)  
[README recommended content: IHEID](https://libguides.graduateinstitute.ch/rdm/readme)

<br>

### üìì Metadata

You will hear the term metadata (data about data) used a lot, especially around archiving your data. Metadata "provide information about the dataset to help people find, understand, and use your data" ([IES](https://ies.ed.gov/funding/datasharing_faq.asp))". Metadata (in addition to a DOI number) aids in finding your data through internet searches. Within education, there are generally two types of metadata: Project-level and file-level.

Project Metadata example fields:

* Title
* Description
* Keywords
* Coverage (spatial and temporal)
* Contacts
* Funders
* Language
* DOI

File Metadata example fields:

* File name
* File format
* Software used to create the files
* Date of creation/ update
* Relationships between files

Many fields have their own metadata standards that aid in the retrieving and indexing of your data. For example social science often follows the Data Documentation Initiative ([DDI](https://ddialliance.org/) standards. However, IES states that education has no standards and they recommend making "notation as interpretable as possible". They also suggest embedding metadata either within the data file or it can be included in a separate file such as a .pdf or your README file.

If you do plan to archive your data, the data repository you plan to use may have standards in place that you will need to follow. Consult your repositories website for detailed information on what is required for archival. Many universities have archives that are available for use and IES also has recommended data repositories that can be found [here](https://ies.ed.gov/funding/datasharing_faq.asp).

* Additional Resources
  + [Metadata: UCI](https://guides.lib.uci.edu/datamanagement/describe)  
  + [Metadata: Cornell](https://data.research.cornell.edu/content/readme#recommendedcontent)
  + [Metadata: Archaeology](https://guides.archaeologydataservice.ac.uk/g2gp/CreateData_1-2#ref-CreateData_1-2-9)
  + [Metadata: Portland](https://libguides.up.edu/datamanagement/documentation)
  + [Metadata: NC](https://www.lib.ncsu.edu/do/data-management/metadata)

<br>

### üìì Miscellaneous

Last you should consider documenting **all** your data processes. This may fit into one of the above mentioned documents, or it may be a separate text or markdown files (such as a README), a syntax file, or even an excel file. Keep this document in the folder related to the content and name it accordingly, Ex:`README_Name-of-process.txt`. Consider tracking things such as:

File origination information:

* You received 10 files from a school district (when did you receive these, why did you receive these)
  + That school district sent you an updated version of 3 of those files one week later (when did you receive these, why did you receive these--were there errors in the previous documents?)
* This kind of information is easy to track if you use versioning software such as Git or you use software that includes versioning such as SharePoint or Box because it allows you to comment each time you commit or save new files.

* Processes used to clean/create data (inputs and outputs) such as:

  + Syntax: `cleaning.R`
  + Input: `district-data_raw_2020_09_08.xlsx`
  + Output: `district-data_clean_2020_10_09.csv`

* Processes to create tables and reports such as:

* To create this report you need to
  + Step 1: Run the file `01_clean-the-data.R`
  + Step 2: Run the file `02_check-errors.R`
  + Step 3: Run the report `code 03_report.R`
  
* And last, as mentioned above, if your team does not use a wiki, consider documenting file naming, file structure, and versioning rules in a document such as a README that is placed in your main project folder. See **File Struture** in Training 2 for more information on these types of rules.

<br>
  
### üìì Documentation Resources

[Naming Files]
[Naming Files]
[Data Dictionary]
[ReadME]

[ICPSR Codebook](https://www.icpsr.umich.edu/icpsrweb/content/shared/ICPSR/faqs/what-is-a-codebook.html)  
[Coding2Share](https://coding2share.github.io/ReproducibilityToolkit/Mod4Document.html#readme) 
[University of Wisconsin-Madison](https://researchdata.wisc.edu/dmp-3-data-documentation/)  
[ICPSR Archving Manual](https://www.icpsr.umich.edu/files/deposit/dataprep.pdf)  
[Foundational Practices of Research Data Management](https://riojournal.com/article/56508/)  
[Longitudinal Comparison Using DDI](https://ddialliance.org/sites/default/files/EnablingLongitudinalDataComparisonUsingDDI.pdf)  
[Data Management for Researchers book](https://pelagicpublishing.com/products/data-management-for-researchers-briney)  
  
