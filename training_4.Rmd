---
title: "Data Cleaning Plan"
output: 
  html_document:
    css: "css/custom.css"
    toc: TRUE
    toc_float: TRUE
    anchor_sections: FALSE
---
  
<br>

:::presentation
<br>
You can view slides from this talk TBD
:::

**This module is a work in progress.**


---

## Overview

---

Data cleaning or data wrangling is the process of organizing and transforming raw data into a dataset that can be easily accessed and analyzed. A data cleaning plan is a written proposal, usually created by a data manager, for how you plan to transform your raw data into the clean, usable data. Think of this as a roadmap. This is different than a code file or even a pseudocode file in that there is no code or syntax in a data cleaning plan. It is just a plain text explanation for the transformations and checks you intend to do with a raw data file. It can be saved in any format that works for you, .txt, .docx, .md, etc. You can even write it in a code file (ex: .R) through comments if you wish, and I often do, as long as reading your comments is not code or technical skills dependent. Anyone from a project coordinator to a programmer should be able to read and understand this file and provide feedback if needed. A data cleaning plan is started prior to data collection, however, similar to every other piece of documentation, this is also a living document that will be updated as you obtain more knowledge. 

An example of a **very** simplified cleaning plan:


*Data cleaning plan for project-a student survey*

1. Import raw data
1. Check structure (# of rows and cols)
    + Check rows for duplicate participants or non-consented participants who need to be removed
      + Compare against a roster (participant tracking)
    + Check cols against data dictionary
      + Any additional variables not in data dictionary?
      + Missing any variables?
1. Check variable classes
    + Update classes as needed
1. Rename variables according to data dictionary
1. Recategorize open-ended variables d and f
1. Reverse coded variable a, b, c
    + Name new variables according to data dictionary
    + Check reverse scoring
1. Create sum and mean scores x, y, and z
    + Name new variables according to data dictionary
1. Add variable labels and value codes for all variables
1. Run validation to check ranges of all variables
1. Export clean data file

---

## Foundation

---

In order to start a data cleaning plan, you need to have the following:

1. Data literacy
2. Domain knowledge
3. Software knowledge 
4. Consultation with stakeholders

### Data literacy

Data cleaning requires a solid foundation around [data literacy](https://en.wikipedia.org/wiki/Data_literacy), the ability to create, interpret, and communicate data as information. Without data literacy it is difficult to visualize how to transform the raw data you have into the format that you need to answer your questions.

While we hope data literacy and good data management permeates every step of the data lifecycle, including data collection, neat data is rarely handed to you, and oftentimes you are taking a file that is mostly unusable and converting it to something useful. 

Here are ways to build data literacy, adapted from [Venngage](https://venngage.com/blog/data-literacy/):

1. Recognize that data errors are inevitable. Despite your best efforts to collect clean data, issues such as duplicate records, illegal values, or missing data still occur ([Hubbard, 2017](https://files.eric.ed.gov/fulltext/ED583982.pdf)). 
2. Know the types of data you are working with (quantitative, qualitative)
3. Understand the source of where your data comes from (primary data sources, secondary data sources) and also how data is created (aggregation, calculations, etc.)
4. Keep your data organized (understand data structure)
5. Know how to look for patterns and outliers in data, and be aware of your own biases.
6. Use Exploratory Data Analysis (EDA) to validate data
7. The more data you work with, the more you learn

 ðŸ“‘ Additional [resource](https://hbr.org/2020/02/boost-your-teams-data-literacy) on boosting data literacy

### Domain knowledge

A lot of data literacy also relies on domain knowledge or ghost knowledge(https://counting.substack.com/p/whys-it-hard-to-teach-data-cleaning), information you only learn from being immersed in a field. Examples of domain knowledge I have acquired from being in the field of education research include:

  + If researchers tell me they are analyzing longitudinal data, I know I need to account for time in the data in some way (ex: add a time variable). If researchers are clustering data, I know I need to account for that cluster in the data in some way (ex: add a cohort variable). I know if we have multiple forms or forms across time, we have to link our data and I need to add a unique study id to link data.

  + There are school districts we work with that send us student level discipline data (ex: number of OSS or ISS referrals). They do not have codebooks or data dictionaries for these data. However, I know from working with these districts and having conversations with them, that if there are no referrals for a student, they leave a cell blank (rather than enter a zero). If I did not have this domain knowledge, I would assume the information is simply missing.

   + Similarly, I know from working with certain districts as well as state education agencies and having conversations with them, that how state test scores are collected or scored have changed across years (state and district). Again, most of these agencies don't usually have codebooks or data dictionaries but I have learned this through conversations and by noticing differences in score ranges over time.
   
   + Again, from working with districts and states, I know to prepare for inconsistencies in data. I've seen variable names change over time. I've also seen the variables collected change over time. And sometimes, across time, variables with the exact same name are no longer measuring the same thing (another reason why documentation is so important).


### Software knowledge

I know what you may be thinking here. Earlier I said that the interpretation of a data cleaning plan should not require any technical knowledge. This is still true. However, the person who writes the data cleaning plan still needs to have a basic understanding of how the software that is used to collect the data and any software that will be used to clean or analyze the data. This knowledge will inform the steps you add to a data cleaning plan.

Become familiar with the following:
1. The tools used to collect data  

  - Is it online software?  
    - If yes, is the data exported? What file type is exported?  
    - Can you connect to the data through other means (ex: API)?  
    - How are values coded (numeric or words)?  
    - How are missing values coded?  
    - What are the additional variables this software adds to an export file that we don't need for our clean data?  
    - How are "select all" questions exported?  
      - For example I know when Qualtrics collects data from a "select all" question
        a) the data will export in multiple columns like the question below where we asked, "Which tools do you use for remote teaching?"
        b) Yes will be coded as 1 and No will be exported as NAs
    - Extract sample data to get a feel for all of this!  
      
```{r echo=FALSE, message=FALSE, warning=FALSE, out.width='10%', out.height= '50%'}

library(tidyverse)

tibble::tribble (~ Q1_1, ~ Q1_2, ~Q1_3, ~Q1_4,
                 NA, 1, NA, NA,
                 NA, 1, 1, 1,
                 NA, NA, NA, NA,
                 1, 1, 1, NA) %>%
gt::gt()
  
```

<br>

  - Is the data hand entered from paper forms?
    - How is the data entered/exported? File type?
    - What funky formatting things does that software do?
      - Excel loves to [autocorrect](https://www.theverge.com/2020/8/6/21355674/human-genes-rename-microsoft-excel-misreading-dates) numeric or character values to dates for example
2. What software are we using to clean the data?
    - Is the software case sensitive?
    - Does it have variable name limits?
    - Does it have other limitations on variable names (can't start with a number)?
3. What software do stakeholders plan to use to analyze the data? **Note we may not always know this, but if we do, we can try to accommodate this
    - Is there a certain file type required for data import?
      - For example, [Mplus](https://stats.idre.ucla.edu/mplus/seminars/mplus-class-notes/entering/) can only read ASCII text files
    - What missing values are allowed
      - Again with [Mplus](https://tutorials.methodsconsultants.com/posts/preparing-data-for-mplus/), it doesn't allow blanks in a data file so all missing values need to be replaced with an actual value (ex: -99)
    - With all this said, don't just tailor your output clean file to a particular user. Depending on a users needs, you may export two clean files, one for that user and another general clean analysis file in a file type that will be accessible to anyone and is best for long term preservation. While we will talk more about this in later trainings around data sharing, non-proprietary data formats such as [csv or txt](https://dmptool.org/general_guidance#file-formats) are best.
 

### Consultation with stakeholders

While everything above is absolutely imperative to the data cleaning process, this may actual be the most important step in developing a data cleaning plan. If you don't know a) how your data is collected, and b) how researchers plan to analyze the data, you have no roadmap for data cleaning. This is where you learn things such as:

1. The types of data you will be receiving (survey, observation, assessment) 
1. What format it will be in (csv, xlsx, spss)
1. How reliable is the data (will it be hand entered, is it collected by our team, is it coming from an outside source)
1. What is the timeline? When should the data team expect to receive data?
1. How do researchers intend to use the data
1. Do researchers want their final data in long or wide form
1. Do they need missing data coded in any specific way
1. What file format do they need
1. Any additional calculations or transformations that need to be done in the data
1. Any other secondary data sources they want brought in to enhance the data
1. What is the timeline for when researchers need clean data

This initial meeting with stakeholders, prior to data collection or even prior to building data collection tools, is a great time to start your documentation. This should not just be one initial meeting though. While the PIs may only need to be brought in at the beginning, a data manager should meet with the coordinators more frequently to monitor changes to the data collection instruments, any new measures added, changes in data collection protocol, any anticipated hiccups. After data is cleaned, data teams should consider having data reviews with project coordinators to cover what data issues were encountered and what could we have done better.


---

## Data Structure

---

Before we can start writing our data cleaning plan, we need to understand what structure we need our data to be in for analysis. 

In the world of quantitative education research, we are most likely trying to create rectangular datasets (rows and columns), rather than having data in text files, video recordings, xml, etc. Even in qualitative research, we are often wrangling data to be in a format that is analyzable and allows categorization.

The two ways data will need to be structured for the field of education are wide or long. The simplest way to think about wide is that all data collected on a unique participant will be in one row. The easiest scenario to see this is with repeated measure data. If we collect a survey on participants in wave 1 and 2, those waves of data will all be in the same row (merged together) and each wave of data collection will be appended to a variable name to create unique variable names.

```{r echo=FALSE, message=FALSE, warning=FALSE, out.width='10%', out.height= '50%'}

library(tidyverse)

tibble::tribble (~ stu_id, ~w1_stress1, ~w1_stress2, ~w2_stress1, ~w2_stress2,
                 56987, 3, 4, 2, 3,
                 54882, 1, 1, 1, 2,
                 55574, 2, 1, 4, 1) %>%
gt::gt()
  
```

<br>

In long data, a participant can repeat in your dataset. Again, the most straight forward way to think about this is with repeated measure data, where each row will be a new time point for a participant. This is often called appending data. In this scenario, we no longer need to append the data collection wave to variable names. However, we would need to add a time period variable to denote the wave associated with each row of data.

```{r echo=FALSE, message=FALSE, warning=FALSE, out.width='10%', out.height= '50%'}

library(tidyverse)

tibble::tribble (~ stu_id,  ~wave, ~stress1, ~stress2,
                 56987, 1, 3, 4,
                 56987, 2, 2, 3,
                 54882, 1, 1, 1, 
                 54882, 2, 1,2,
                 55574, 1, 2, 1, 
                 55574, 2, 4, 1) %>%
gt::gt()
  
```

<br>

There are different reasons for constructing your data one way or another. For example, repeated measure procedures typically require data to be in wide format, where the unit of analysis is the subject. While mixed model procedures typically required data to be in long format, where the unit of analysis is each measurement for the subject.

The thing is, it is **very** easy to restructure data from one way to another. So my opinion is, the easiest way to manage data is to not merge data until you have to. It is much simpler, in terms of data management and syntax writing, to keep variable names consistent over time.

* Don't merge your data files together until you absolutely need to (you need it or someone requests it). * Don't append any time periods to variable names or add a time variable to your data until you have to (this can all be added very easily in your syntax). You will know what time period is associated with the data file based on the file name and storage location.

Once someone requests data or you need it for your own purposes, then you can add a time variable or append time to variables. Just make sure to ask the requestor what format they want their data in.

 ðŸ“‘ The Analysis Factor has a great [blog post](https://www.theanalysisfactor.com/wide-and-long-data/) on things to consider when choosing between long and wide format.

<br>

### Merging across forms

Most of what I mentioned above refers to how to structure data over time. However, we also need to discuss how to merge disparate data sources within time. Most likely you will be collecting more than one piece of data from participants. You may have a survey and an assessment for instance. Within time, those forms will always be merged in wide format. You will link a participant's survey data to their assessment data through the unique identifier you've give the participants and attached to each form.

<br>

### Tidy Data

I of course, can not pass over the topic of tidy data here. The term is ubiquitous in the world of data and since I plan to use R for data wrangling in later modules, tidy data needs to be covered. Tidy data, defined by [Hadley Wickham](https://www.jstatsoft.org/article/view/v059i10), meets very specific conditions which are:

1. Each variable forms a column
2. Each observation forms a row
3. Each type of observational unit forms a table

In a nutshell, tidy data are long format data.

|Not tidy data               |  Tidy data  |
|:--------------------------:|:-----------:|
|![](img/not-tidy-data.png)  |![](img/tidy-data.png)|

I think in education research, tidy data definitely has a time and place (for example in creating visualizations/graphs, and some analyses). And as I mentioned earlier, this is the most clean way to store your data since variable names aren't repeating and changing based on things like time periods. However, I think what is most important is organizing your data in the rectangular format (rows and columns) that is necessary for your analysis. I also think it is important to follow some of the other guidelines set forth by Hadley Wickham, and also by Karl Broman and Kara Woo in their paper [Data Organization in Spreadsheets](https://kbroman.org/dataorg/).

Important guidelines to follow:

1. Put just one thing in a cell  
    + Ex: If a rate column contains two numbers, cases/enrollment
    + Split that column into two columns (cases and enrollment)

|Two things one cell              |  Two things two cells |
|:--------------------------:|:-----------:|
|![](img/two-in-one.png)  |![](img/two-in-two.png)|

2. Make your data a rectangle  
    + The first row of your data should be variable names (only one row for this)
    + The remaining data should be rows and columns that correspond to subjects and variables
  
|Not rectangle              |  Rectangle |
|:--------------------------:|:-----------:|
|![](img/not-rectangle.png)  |![](img/rectangle.png)|

Just be prepared because while you may put in the planning to collect organized data, many of the secondary datasets you use will not be organized in a nice rectangle for you. But don't worry! You can transform the dataset on the left into the one on the right with a little patience, planning, and syntax. You can find more examples of non-rectangular data from Karl Broman [here](https://kbroman.org/dataorg/pages/rectangle.html).

3. Don't use font color or highlighting as data  
    + If you want to flag data as suspicious, add a variable to indicate that

|Highlight            |  No highlight|
|:--------------------------:|:-----------:|
|![](img/highlight.png)  |![](img/no-highlight.png)|

Resources:

  ðŸ“‘ [Karl Broman](https://kbroman.org/dataorg/)  
  ðŸ“‘ [R for Data Science](https://r4ds.had.co.nz/tidy-data.html)  
  ðŸ“‘ [Tidy Data](https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/0012-9623-90.2.205)  

<br>

### Final Datasets

In the end, what you will most likely want is one dataset per participant entity (school dataset, teacher dataset, student dataset). And if you plan to link these together, you will need to make sure you are able to do that through your ID schema.

```{r, echo=FALSE, fig.align="center", out.width='65%'}

knitr::include_graphics("img/id_schema.png")

```


---

## Data Cleaning Steps

---

Our role as data managers is not to think of every possible iteration of how an analyst/researcher may want their data or every variable they may need. However, it is our role to reduce the amount of work required to get that data into an analyzable format.  Below I lay out some of the go-to steps I like to add to a data cleaning plan and the reasoning behind why I think they are important.

First rule: Never touch the raw data. You never know when you will make an error and need to return to the the uncorrected data file. https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/0012-9623-90.2.205
Second rule: Keep everything (except variables that are identifying and completely unnecessary for project) both item level and aggregated data 


  ðŸ“‘ Jeff Leek has a great [blog post](https://simplystatistics.org/2019/05/29/research-quality-data-and-research-quality-databases/) on creating research quality datasets.

---

## Reproducible Syntax

---

Over the years I have seen researchers manually clean code....